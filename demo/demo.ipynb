{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ============================================================\n",
    "# =============Big Data Science: Project demo (May 2020)============\n",
    "# ============================================================\n",
    "## Study of COVID-19 denialism through twitter activity\n",
    "### Project group 26:  Wannes Van Leemput, Sam Vanmassenhove\n",
    "\n",
    "In this project we study the phenomenon of \"COVID-denialism\", meaning people who, despite all evidence to the contrary, refuse to acknowledge the coronavirus as a serious threat to society, often referring to it as a \"hoax\". \n",
    "\n",
    "We searched corona-related tweets for signs of denialism and created a labelled training set based on the hashtags used by such denialists. The training data was then used to train a classification model in order to predict whether a certain tweet was a case of COVID denial or a regular tweet on the subject of coronavirus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession, Row\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import sys\n",
    "sys.path.append('../python files')\n",
    "\n",
    "# Import our own code\n",
    "from Authentication import Authentication\n",
    "from DataMiner import DataMiner\n",
    "from PreProcessTweets import PreProcessTweets\n",
    "from TweetDataIO import TweetDataIO\n",
    "from DenialPredictor import DenialPredictor\n",
    "from datastream_test import MyStreamListener\n",
    "from Visualisation import Visualisation\n",
    "from LocationService import LocationService\n",
    "\n",
    "# Create a set of English stopwords\n",
    "sw = set(stopwords.words(\"english\")) \n",
    "\n",
    "# Initiate spark\n",
    "sc = SparkContext('local[*]')\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Get twitter api authentication\n",
    "api = Authentication().get_api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification of denialist tweets\n",
    "### 1.1 Demonstration of tweet searching and IO\n",
    "\n",
    "We use the Tweepy library to search tweets. We focus on English language tweets as these are most common and more geopgraphically diverse.\n",
    "\n",
    "Note that the training set should already exist as a saved CSV-file when running this \"application\" in production. The following code is only for the purpose of demonstrating the IO functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tag: #COVID1984\n",
      "Processing tag: #BillGatesIsEvil\n",
      "Processing tag: #coronaHoax\n",
      "Processing tag: #FilmYourHospital\n",
      "Processing tag: #scamdemic\n",
      "Processing tag: #Plandemic2020\n",
      "Processing tag: #POTUS\n",
      "Processing tag: #QAnon\n",
      "Processing tag: #ResistTheNewWorldOrder\n",
      "Processing tag: #BillGates\n",
      "Processing tag: #CORONAHOAX\n",
      "Processing tag: #plandemic\n",
      "Processing tag: #Coronabollocks\n",
      "Processing tag: #sos\n",
      "Processing tag: #WWG1WGA\n",
      "Processing tag: #coronabollocks\n",
      "Processing tag: #NWO\n",
      "Processing tag: #Scamdemic\n",
      "Processing tag: #CovidHoax\n",
      "Processing tag: #q\n",
      "Processing tag: #woke\n",
      "Processing tag: #thegreatawakening\n",
      "Processing tag: #DrainTheSwamp\n",
      "Processing tag: #Coronahoax\n",
      "Processing tag: #BillGatesBioTerrorist\n",
      "Processing tag: #endthelockdown\n",
      "Processing tag: #ObamaGate\n",
      "Processing tag: #FakePandemic\n",
      "Processing tag: #Plandemic\n",
      "Processing tag: #coronahoax\n",
      "Processing tag: #CoronaHoax\n"
     ]
    }
   ],
   "source": [
    "# Mine some denial tweets (no specific location)\n",
    "control_tags = [\"#Covid_19\", \"#coronavirus\", \"#COVIDãƒ¼19\", \"#COVID19\", \"#coronavirusNYC\", \"#coronavirusoregon\", \n",
    "             \"#lockdown\", \"#covid19\", \"#COVID\", \"#pandemic\", \"#Corona\", \"#Covid19\", \"#CoronaVirus\"]\n",
    "miner = DataMiner(api, \"#CoronaHoax\", \"\", \"en\", tagignore=control_tags, num_tweets=300)\n",
    "denial_tweets = miner.mine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing tag: #Covid_19\n",
      "Processing tag: #Coronavirus\n",
      "Processing tag: #COVID19\n",
      "Processing tag: #coronavirus\n"
     ]
    }
   ],
   "source": [
    "# Mine some control tweets (no specific location)\n",
    "hoax_tags = [\"#CoronaHoax\", \"#covidhoax\",\"#coronahoax\", \"#covidhoax\", \"#Plandemic\"]\n",
    "miner = DataMiner(api, \"coronavirus\", \"\", \"en\", tagignore=hoax_tags, num_tweets=1000)\n",
    "control_tweets = miner.mine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal newline in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal newline in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n",
      "Warning: illegal delimiter ';' in name or location.\n"
     ]
    }
   ],
   "source": [
    "# Write the tweets to a CSV file\n",
    "filename = \"./training_data.txt\"\n",
    "io = TweetDataIO(filename, spark=spark, context=sc)\n",
    "io.write(denial_tweets, label=0, append=False)\n",
    "io.write(control_tweets, label=1, append=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note: the cell below may give an error. This is likely a problem with a recent pyspark version and may not occur on your machine. If it does, just run the below cell again manually and it should work..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "|label|           location|                tags|                text|               time|           tweet_id|         user|\n",
      "+-----+-------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "|    0|                USA|#CoronaHoax|#Plan...|Another BS poll, ...|2020-05-20 20:28:52|1263205068461019138|   informusa1|\n",
      "|    0|                USA|#CoronaHoax|#Plan...|This is not news,...|2020-05-20 20:27:00|1263204598644383744|   informusa1|\n",
      "|    0|                   | #COVID1984|#WWG1WGA|@Under_Our_Watch ...|2020-05-20 20:25:20|1263204181482995712|  DeepDrainer|\n",
      "|    0|         Washington|#COVID19|#Coronav...|So policy enforce...|2020-05-20 20:24:33|1263203984258588672| JeffHannMADA|\n",
      "|    0|                USA|#CoronaHoax|#Plan...|Most cases in a d...|2020-05-20 20:22:45|1263203530053214208|   informusa1|\n",
      "|    0|                   |#Covid1984|#coron...|Yaâ€™ll should win ...|2020-05-20 20:11:11|1263200618681782272|  kelseeydawn|\n",
      "|    0|       Portland, OR|          #COVID1984|Pa. school direct...|2020-05-20 19:59:09|1263197592491397120|chrisclark503|\n",
      "|    0|Keystone State ðŸš‚ðŸ’¨|          #COVID1984|@maggieallen47 @s...|2020-05-20 19:57:43|1263197230233784323| ScaterdFewXP|\n",
      "|    0|     Vero Beach, FL|          #COVID1984|Remember this jus...|2020-05-20 19:56:55|1263197031285301251|     fleyeguy|\n",
      "|    0|                   |#10:|#EndTheLockd...|WTMWD #10: The Fr...|2020-05-20 19:42:35|1263193420085878784|     Bretigne|\n",
      "+-----+-------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read same file and show\n",
    "ddf = io.read()\n",
    "ddf.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "|label|            location|                tags|                text|               time|           tweet_id|         user|\n",
      "+-----+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "|    0|          Texas, USA|#WakeUpAmerica|#W...|I think people wi...|2020-05-13 19:07:19|1260647830344962048| kristintoday|\n",
      "|    0|                    |#Covid19|#FilmYou...|Tanzanian Preside...|2020-05-15 01:28:01|1261106024347508738|    nurudinho|\n",
      "|    0|                    |#CoronaHoax|#Fake...|@Stinky_Sausage5 ...|2020-05-15 20:20:53|1261391119704707072| OManHereWeGo|\n",
      "|    0|                    |\"\"\"#Corona\"\"|#Cor...|\"@DonovanTim @San...|2020-05-16 20:24:40|1261754459895537665|        Si93B|\n",
      "|    0|N.W. England nr m...|     #Coronabollocks|#Coronabollocks I...|2020-05-17 15:48:55|1262047453592813569|    dave80743|\n",
      "|    0|               Beach|     #Coronabollocks|@adamcarolla @Act...|2020-05-17 18:04:06|1262081474565738497|     ccoffee1|\n",
      "|    0|Colorado Springs, CO|#BillGatesIsEvil|...|@Laurianna90 Good...|2020-05-19 16:17:34|1262779441299652608|   cryptolili|\n",
      "|    0|                    |#FakePandemic|#En...|LOL well isn't th...|2020-05-19 17:47:45|1262802133872709635|   BenignSage|\n",
      "|    0|         Olathe,  KS|#SleepyCreepyJoe|...|Awwww...poor #Sle...|2020-05-19 19:15:27|1262824207261540353|  ManganSusan|\n",
      "|    0|             USAðŸ‡ºðŸ‡¸|#BillGatesIsEvil!...|@realJediMan1 @Mi...|2020-05-19 21:51:30|1262863477590429697|country4trump|\n",
      "+-----+--------------------+--------------------+--------------------+-------------------+-------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicates \n",
    "ddf = ddf.orderBy(\"label\").dropDuplicates([\"tweet_id\"])\n",
    "ddf.show(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Perform preprocessing steps on the tweets to prepare for classification model\n",
    "We use PySpark dataframes to store the most important tweet information, namely the text, location, time and user. The tweet text can be preprocessed by removing punctuation, stop-words, hashtags, user mentions and hyperlinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      ">> Removing stopwords...\n",
      ">> Removing urls...\n",
      ">> Removing hashtags...\n",
      ">> Removing user mentions...\n",
      ">> Removing punctuation...\n",
      ">> Removing whitespace...\n",
      "Finished preprocessing!\n"
     ]
    }
   ],
   "source": [
    "p = PreProcessTweets(ddf, \n",
    "                     remove_tags=True, \n",
    "                     remove_mentions=True, \n",
    "                     remove_punctuation=True, \n",
    "                     remove_urls=True, \n",
    "                     remove_stopwords=True)\n",
    "ddf = p.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>location</th>\n",
       "      <th>tags</th>\n",
       "      <th>text</th>\n",
       "      <th>time</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>user</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>#WakeUpAmerica|#WakeUp|#HumanityIsNotAVirus|#B...</td>\n",
       "      <td>I think people will finally start to wake up w...</td>\n",
       "      <td>2020-05-13 19:07:19</td>\n",
       "      <td>1260647830344962048</td>\n",
       "      <td>kristintoday</td>\n",
       "      <td>I think people finally start wake kids taken h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#Covid19|#FilmYourHospital|#EndTheShutdown|#KOT</td>\n",
       "      <td>Tanzanian President Pombe Maghufuli confirms t...</td>\n",
       "      <td>2020-05-15 01:28:01</td>\n",
       "      <td>1261106024347508738</td>\n",
       "      <td>nurudinho</td>\n",
       "      <td>Tanzanian President Pombe Maghufuli confirms s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>#CoronaHoax|#FakePandemic|#FilmYourHospital|#F...</td>\n",
       "      <td>@Stinky_Sausage5 In 2017 Fauci said that there...</td>\n",
       "      <td>2020-05-15 20:20:53</td>\n",
       "      <td>1261391119704707072</td>\n",
       "      <td>OManHereWeGo</td>\n",
       "      <td>In 2017 Fauci said surprise outbreak Trump adm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>\"\"\"#Corona\"\"|#CoronaVirus|#Covid19|#EmptyHospi...</td>\n",
       "      <td>\"@DonovanTim @SandraWors3 @TommyCorbyn @GetBre...</td>\n",
       "      <td>2020-05-16 20:24:40</td>\n",
       "      <td>1261754459895537665</td>\n",
       "      <td>Si93B</td>\n",
       "      <td>Heres Chief Medical Officer UK admitting recor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>N.W. England nr mcr airport</td>\n",
       "      <td>#Coronabollocks</td>\n",
       "      <td>#Coronabollocks It most certainly is and anywa...</td>\n",
       "      <td>2020-05-17 15:48:55</td>\n",
       "      <td>1262047453592813569</td>\n",
       "      <td>dave80743</td>\n",
       "      <td>It certainly anyway lagers Poofs Ooops sorry w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                     location  \\\n",
       "0      0                   Texas, USA   \n",
       "1      0                                \n",
       "2      0                                \n",
       "3      0                                \n",
       "4      0  N.W. England nr mcr airport   \n",
       "\n",
       "                                                tags  \\\n",
       "0  #WakeUpAmerica|#WakeUp|#HumanityIsNotAVirus|#B...   \n",
       "1    #Covid19|#FilmYourHospital|#EndTheShutdown|#KOT   \n",
       "2  #CoronaHoax|#FakePandemic|#FilmYourHospital|#F...   \n",
       "3  \"\"\"#Corona\"\"|#CoronaVirus|#Covid19|#EmptyHospi...   \n",
       "4                                    #Coronabollocks   \n",
       "\n",
       "                                                text                 time  \\\n",
       "0  I think people will finally start to wake up w...  2020-05-13 19:07:19   \n",
       "1  Tanzanian President Pombe Maghufuli confirms t...  2020-05-15 01:28:01   \n",
       "2  @Stinky_Sausage5 In 2017 Fauci said that there...  2020-05-15 20:20:53   \n",
       "3  \"@DonovanTim @SandraWors3 @TommyCorbyn @GetBre...  2020-05-16 20:24:40   \n",
       "4  #Coronabollocks It most certainly is and anywa...  2020-05-17 15:48:55   \n",
       "\n",
       "              tweet_id          user  \\\n",
       "0  1260647830344962048  kristintoday   \n",
       "1  1261106024347508738     nurudinho   \n",
       "2  1261391119704707072  OManHereWeGo   \n",
       "3  1261754459895537665         Si93B   \n",
       "4  1262047453592813569     dave80743   \n",
       "\n",
       "                                      processed_text  \n",
       "0  I think people finally start wake kids taken h...  \n",
       "1  Tanzanian President Pombe Maghufuli confirms s...  \n",
       "2  In 2017 Fauci said surprise outbreak Trump adm...  \n",
       "3  Heres Chief Medical Officer UK admitting recor...  \n",
       "4  It certainly anyway lagers Poofs Ooops sorry w...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas and have a look at the new data\n",
    "df = ddf.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Training and evaluation of classification model\n",
    "We train a machine learning classification model with \"sklearn\" in order to classify tweets. The effects of the preprocessing is investigated, as is the effect of replacing the simle Naive Bayes Classifier by a SVM model.\n",
    "#### 1.3.1 First try on the original unedited text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance : \n",
      "Accuracy: 0.920,\n",
      "Precision: 0.941, \n",
      "Recall: 0.788,\n",
      "F1: 0.857\n",
      "Test set performance : \n",
      "Accuracy: 0.816,\n",
      "Precision: 0.751, \n",
      "Recall: 0.532,\n",
      "F1: 0.623\n"
     ]
    }
   ],
   "source": [
    "# Split data (corpus and labels) into train and test sets\n",
    "predictor = DenialPredictor(corpus=df.processed_text, labels=df.label, clf=\"nb\")\n",
    "X_train, X_test, y_train, y_test = predictor.train_test_split(split=0.3)\n",
    "\n",
    "# Fit the model\n",
    "predictor.fit_model(X_train, y_train)\n",
    "\n",
    "# Calculate some metrics to evaluate performance\n",
    "print(\"Training set performance : \")\n",
    "predictor.calc_metrics(X_train, y_train)\n",
    "print(\"Test set performance : \")\n",
    "predictor.calc_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Now do the same but without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing...\n",
      ">> Removing stopwords...\n",
      ">> Removing hashtags...\n",
      ">> Removing whitespace...\n",
      "Finished preprocessing!\n",
      "\n",
      "\n",
      "Training set performance : \n",
      "Accuracy: 0.940,\n",
      "Precision: 0.965, \n",
      "Recall: 0.833,\n",
      "F1: 0.894\n",
      "Test set performance : \n",
      "Accuracy: 0.823,\n",
      "Precision: 0.794, \n",
      "Recall: 0.512,\n",
      "F1: 0.622\n"
     ]
    }
   ],
   "source": [
    "# Split data (corpus and labels) into train and test sets\n",
    "predictor = DenialPredictor(df.text, df.label)\n",
    "X_train, X_test, y_train, y_test = predictor.train_test_split(split=0.3)\n",
    "\n",
    "# Fit the model\n",
    "predictor.fit_model(X_train, y_train)\n",
    "\n",
    "# Calculate some metrics to evaluate performance\n",
    "print(\"Training set performance : \")\n",
    "predictor.calc_metrics(X_train, y_train)\n",
    "print(\"Test set performance : \")\n",
    "predictor.calc_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 The same again but this time with a different classifier: Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set performance : \n",
      "Accuracy: 0.911,\n",
      "Precision: 0.963, \n",
      "Recall: 0.737,\n",
      "F1: 0.835\n",
      "Test set performance : \n",
      "Accuracy: 0.806,\n",
      "Precision: 0.748, \n",
      "Recall: 0.485,\n",
      "F1: 0.588\n"
     ]
    }
   ],
   "source": [
    "# Split data (corpus and labels) into train and test sets\n",
    "svm_predictor = DenialPredictor(df.processed_text, df.label, clf=\"svm\")\n",
    "X_train, X_test, y_train, y_test = svm_predictor.train_test_split(split=0.3)\n",
    "\n",
    "# Fit the model\n",
    "svm_predictor.fit_model(X_train, y_train)\n",
    "\n",
    "# Calculate some metrics to evaluate performance\n",
    "print(\"Training set performance : \")\n",
    "svm_predictor.calc_metrics(X_train, y_train)\n",
    "print(\"Test set performance : \")\n",
    "svm_predictor.calc_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data (corpus and labels) into train and test sets\n",
    "svm_predictor = DenialPredictor(df.text, df.label, clf=\"svm\")\n",
    "X_train, X_test, y_train, y_test = svm_predictor.train_test_split(split=0.3)\n",
    "\n",
    "# Fit the model\n",
    "svm_predictor.fit_model(X_train, y_train)\n",
    "\n",
    "# Calculate some metrics to evaluate performance\n",
    "print(\"Training set performance : \")\n",
    "svm_predictor.calc_metrics(X_train, y_train)\n",
    "print(\"Test set performance : \")\n",
    "svm_predictor.calc_metrics(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Live tweet streaming and classification\n",
    "\n",
    "In this section we demonstrate that we can correctly classify denialist tweets when streaming tweets live. A streamer is set up to search twitter for new tweets with the hoax hashtags.\n",
    "\n",
    "We can see that these tweets are for the most part correctly identified, but the classifier is occasionally defeated by irony; satiral tweets are often mistaken for real denialist tweets.\n",
    "\n",
    "The streamed tweets below are labelled (denial or normal), and the label probability is also given between brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from LivePredictionStream import LivePredictionStream\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start streaming...\n",
      "(1) denial (1.00): @mitchellvii @dgaliger2 We all live in hope. Especially the Qanons that gave followed thus really since 2016/7. WWG1WGA ðŸ‡¬ðŸ‡§ ðŸ‡ºðŸ‡¸ #Trump2020 #VoterID #VoterFraud #FlynnFighters #ObamaGate #SubpoenaObama\n",
      "(2) denial (1.00): @BreitbartNews Ofcourse it's denied!\n",
      "(3) denial (1.00): Must-see ðŸ“ºConnecting all the dots - with a great amount of passion I might add. Check out the now banned-for-life from Twitter Edu(ating L1berals blowing it up! #wwg1wga #greatawakening #qanon #qarmy #plandemic #election2020\n",
      "(4) denial (1.00): Do these people care about your well being? Do these people love America?ðŸ‡ºðŸ‡² Do anything to regain power? #NewQ #pandemic #QAnon #PatriotsFight #FakeNews #DrainTheSwamp #KAG2020\n",
      "(5) denial (1.00): @jujo28 @washingtonpost #CreepyJoeBiden and #ObamaGate created division for many years. #Trump has brought unity among Patriots at a time when America was very polarized politically and racially. #QHatTip #BidenBeHidin from embarrassing rallies and debates conveniently from this #Covid #Plandemic.\n",
      "Stopped.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "FILE_NAME = \"hoax.csv\"\n",
    "api = Authentication(isApp=False).get_api()\n",
    "auth = api.auth\n",
    "streamListener = LivePredictionStream(FILE_NAME, predictor, num_iter=5, verbose=1, tagignore=tagignore)\n",
    "stream = tweepy.Stream(auth=auth, listener=streamListener)\n",
    "\n",
    "try:\n",
    "    print('Start streaming...')\n",
    "    stream.filter(languages=['en'], \n",
    "                    track=tagignore)\n",
    "\n",
    "except Exception:\n",
    "    print(\"Stopped.\")\n",
    "\n",
    "finally:\n",
    "    stream.disconnect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### 3.1 Aquiring tweet location data\n",
    "\n",
    "Tweet data is aquired and preprocessed. Preprocessed includes geocoding the author location. Since a free api is used, we are limited to 1 request per second. Due to this, the geocoding can take a while (>20 min if training set is large).\n",
    "\n",
    "#### Note: this code will throw Exceptions and warnings. This is normal, and is because we are using the free version of the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Aether',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Jalandhar',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Florida, USA',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n",
      "RateLimiter caught an error, retrying (0/2 tries). Called with (*('Las Vegas, NV',), **{}).\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1319, in do_open\n",
      "    encode_chunked=req.has_header('Transfer-encoding'))\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1252, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1298, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1247, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 966, in send\n",
      "    self.connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 1414, in connect\n",
      "    super().connect()\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\http\\client.py\", line 938, in connect\n",
      "    (self.host,self.port), self.timeout, self.source_address)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 728, in create_connection\n",
      "    raise err\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\socket.py\", line 716, in create_connection\n",
      "    sock.connect(sa)\n",
      "socket.timeout: timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 367, in _call_geocoder\n",
      "    page = requester(req, timeout=timeout, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 525, in open\n",
      "    response = self._open(req, data)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 543, in _open\n",
      "    '_open', req)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 503, in _call_chain\n",
      "    result = func(*args)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1362, in https_open\n",
      "    context=self._context, check_hostname=self._check_hostname)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\urllib\\request.py\", line 1321, in do_open\n",
      "    raise URLError(err)\n",
      "urllib.error.URLError: <urlopen error timed out>\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\extra\\rate_limiter.py\", line 126, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\osm.py\", line 408, in geocode\n",
      "    self._call_geocoder(url, timeout=timeout), exactly_one\n",
      "  File \"C:\\Users\\SamVa\\AppData\\Local\\Continuum\\anaconda3\\envs\\bds\\lib\\site-packages\\geopy\\geocoders\\base.py\", line 394, in _call_geocoder\n",
      "    raise GeocoderTimedOut('Service timed out')\n",
      "geopy.exc.GeocoderTimedOut: Service timed out\n"
     ]
    }
   ],
   "source": [
    "locationservice = LocationService()\n",
    "filename = \"./training_data.txt\"\n",
    "io = TweetDataIO(filename, spark=spark, context=sc)\n",
    "ddf = io.read()\n",
    "df = ddf.toPandas()\n",
    "df = locationservice.add_location_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Visualise global trending hashtags\n",
    "Global trending hashtags amongst hoax-believer tweets are shown, along with their occurance count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city = \"New York City\"\n",
    "country = \"USA\"\n",
    "radius = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis=Visualisation(df)\n",
    "vis.trending_tags_local(city, country, radius)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Visualise hoax believers\n",
    "The location of hoax believers can be shown on a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis.heat_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
